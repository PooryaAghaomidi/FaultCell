{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Set base configurations"
   ],
   "metadata": {
    "id": "nHEZxo65A3-i"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FGW4-7N7A0aZ",
    "ExecuteTime": {
     "end_time": "2024-09-24T14:45:18.891478Z",
     "start_time": "2024-09-24T14:42:58.752209Z"
    }
   },
   "source": [
    "seed_value= 42\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "metadata": {
    "id": "iomiI7SAC1a-",
    "ExecuteTime": {
     "end_time": "2024-09-24T14:45:20.002470Z",
     "start_time": "2024-09-24T14:45:18.891478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import"
   ],
   "metadata": {
    "id": "vOWo15wYBUzb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Conv2D, Flatten, UpSampling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, BatchNormalization, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GRU, Add, ReLU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers, optimizers, losses\n",
    "from livelossplot.inputs.tf_keras import PlotLossesCallback"
   ],
   "metadata": {
    "id": "fCETuUYQBYWA",
    "ExecuteTime": {
     "end_time": "2024-09-24T14:45:31.605424Z",
     "start_time": "2024-09-24T14:45:20.002470Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialization"
   ],
   "metadata": {
    "id": "Gf7wd3EQChEx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs  = 200\n",
    "batch_size  = 32\n",
    "cls_num     = 8\n",
    "shape       = (1000, 13)\n",
    "lr          = 0.0001\n",
    "opt         = optimizers.Adam(learning_rate=lr)\n",
    "los         = losses.BinaryCrossentropy()\n",
    "mtr         = ['accuracy']"
   ],
   "metadata": {
    "id": "2HBks-vyCjwu",
    "ExecuteTime": {
     "end_time": "2024-09-24T14:45:31.825797Z",
     "start_time": "2024-09-24T14:45:31.606231Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "address = '../Dataset/Main-1000'\n",
    "\n",
    "files = os.listdir(address)\n",
    "random.shuffle(files)\n",
    "l = len(files)\n",
    "\n",
    "data_train = files[:int(0.8*l)]\n",
    "data_test = files[int(0.8*l):int(0.9*l)]\n",
    "data_val = files[int(0.9*l):]\n",
    "\n",
    "steps_per_train = len(data_train)//batch_size\n",
    "steps_per_test = len(data_test)//batch_size\n",
    "steps_per_val = len(data_val)//batch_size"
   ],
   "metadata": {
    "id": "DgCEa8LBE8Cm",
    "ExecuteTime": {
     "end_time": "2024-09-24T14:45:31.857463Z",
     "start_time": "2024-09-24T14:45:31.825797Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data generator"
   ],
   "metadata": {
    "id": "DMjId1dv9WVQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, address, data, shape, batch_size, cls_num, shuffle=True):\n",
    "        self.address    = address\n",
    "        self.data       = data\n",
    "        self.shape      = shape\n",
    "        self.batch_size = batch_size\n",
    "        self.cls_num    = cls_num\n",
    "        self.shuffle    = shuffle\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes       = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.data[k] for k in indexes]\n",
    "        x, y          = self.__data_generation(list_IDs_temp)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)        \n",
    "        \n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        x = np.empty((self.batch_size, int(self.shape[0]), int(self.shape[1])))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            raw_data = np.load(os.path.join(self.address, ID))\n",
    "            sig = np.transpose(raw_data['signals'])\n",
    "            \n",
    "            for idx, row in enumerate(sig):\n",
    "                x[i, :, idx] = (row - row.min()) / (row.max() - row.min())\n",
    "                \n",
    "            y[i]  = int(str(raw_data['label'])[0])\n",
    "\n",
    "        return x, to_categorical(y, num_classes=self.cls_num)\n",
    "\n",
    "\n",
    "train_gen = DataGenerator(address, data_train, shape, batch_size, cls_num)\n",
    "test_gen  = DataGenerator(address, data_test , shape, batch_size, cls_num)\n",
    "val_gen   = DataGenerator(address, data_val  , shape, batch_size, cls_num)"
   ],
   "metadata": {
    "id": "Lqfej_YmBcp0",
    "ExecuteTime": {
     "end_time": "2024-09-24T14:45:31.892652Z",
     "start_time": "2024-09-24T14:45:31.857463Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:45:31.995853Z",
     "start_time": "2024-09-24T14:45:31.892652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_sample = next(iter(test_gen))\n",
    "x_sample = test_sample[0]\n",
    "y_sample = test_sample[1]\n",
    "\n",
    "print('Label: ', y_sample[0])\n",
    "print('Signal max: ', x_sample[1].max())\n",
    "print('Signal min: ', x_sample[1].min())\n",
    "print('Single signal shape: ', x_sample[1][:, 0].shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Signal max:  1.0\n",
      "Signal min:  0.0\n",
      "Single signal shape:  (1000,)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "id": "fFEJYG-GBdI-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model(myshape, cls_num):\n",
    "  inputs = Input(shape=myshape)\n",
    "  \n",
    "  x = Conv1D(filters=128, kernel_size=8, strides=1, activation='relu')(inputs)\n",
    "  x = MaxPooling1D(2)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "  \n",
    "  x = Conv1D(filters=128, kernel_size=8, strides=1, activation='relu')(x)\n",
    "  x = MaxPooling1D(2)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "  \n",
    "  temporal_1 = GRU(128, return_sequences=True)(x)\n",
    "  temporal_1 = GRU(64, return_sequences=False)(temporal_1)\n",
    "  \n",
    "  temporal_2 = GRU(64, return_sequences=False)(x)\n",
    "  \n",
    "  adding = Add()([temporal_1, temporal_2])\n",
    "  adding = ReLU()(adding)\n",
    "  adding = Dropout(0.2)(adding)\n",
    "  adding = Flatten()(adding)\n",
    "  \n",
    "  outputs = Dense(cls_num, activation='softmax')(adding)\n",
    "\n",
    "  return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model = get_model(shape, cls_num)\n",
    "model.compile(optimizer=opt, loss=los, metrics=mtr)\n",
    "model.summary()"
   ],
   "metadata": {
    "id": "Epe7Q_oqBeEr",
    "ExecuteTime": {
     "end_time": "2024-09-24T14:45:37.063079Z",
     "start_time": "2024-09-24T14:45:31.995853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1000, 13)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 993, 128)     13440       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 496, 128)     0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 496, 128)    512         ['max_pooling1d[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 496, 128)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 489, 128)     131200      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 244, 128)    0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 244, 128)    512         ['max_pooling1d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 244, 128)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 244, 128)     99072       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 64)           37248       ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    (None, 64)           37248       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 64)           0           ['gru_1[0][0]',                  \n",
      "                                                                  'gru_2[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 64)           0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 8)            520         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 319,752\n",
      "Trainable params: 319,240\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "id": "lzs7DO9MBenF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def callback():\n",
    "  mymonitor = 'val_loss'\n",
    "  mymode    = 'min'\n",
    "\n",
    "  main_chk  = ModelCheckpoint(filepath='checkpoints/base', monitor=mymonitor, mode=mymode, verbose=1, save_best_only=True)\n",
    "  early_st  = EarlyStopping(monitor=mymonitor, mode=mymode, patience=10, verbose=1)\n",
    "  rduce_lr  = ReduceLROnPlateau(monitor=mymonitor, mode=mymode, factor=0.5, patience=5, verbose=1, min_lr=0.00001)\n",
    "  tr_plot   = PlotLossesCallback()\n",
    "\n",
    "  return [main_chk, early_st, rduce_lr, tr_plot]\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=callback(),\n",
    "                    steps_per_epoch  = steps_per_train,\n",
    "                    validation_steps = steps_per_val)"
   ],
   "metadata": {
    "id": "v-XEoecuBfmN"
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.122, max:    0.915, cur:    0.914)\n",
      "\tvalidation       \t (min:    0.116, max:    0.728, cur:    0.696)\n",
      "Loss\n",
      "\ttraining         \t (min:    0.076, max:    0.585, cur:    0.077)\n",
      "\tvalidation       \t (min:    0.156, max:    0.629, cur:    0.169)\n",
      "lr\n",
      "\tlr               \t (min:    0.000, max:    0.000, cur:    0.000)\n",
      "61/61 [==============================] - 15s 251ms/step - loss: 0.0775 - accuracy: 0.9139 - val_loss: 0.1694 - val_accuracy: 0.6964 - lr: 1.2500e-05\n",
      "Epoch 118: early stopping\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "id": "WnhMRDgNBgIN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "testmodel = load_model('checkpoints/base', compile=True)\n",
    "tst_loss , tst_acc = testmodel.evaluate(test_gen, steps = steps_per_test)"
   ],
   "metadata": {
    "id": "h2ceCOoJBicL",
    "ExecuteTime": {
     "end_time": "2024-09-24T15:34:04.772387Z",
     "start_time": "2024-09-24T15:33:33.934960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 21s 2s/step - loss: 0.1568 - accuracy: 0.7232\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:34:04.788024Z",
     "start_time": "2024-09-24T15:34:04.772387Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 10
  }
 ]
}
